{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word embeddings and RNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Consumer complaint narrative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Student loan</td>\n",
       "      <td>In XX/XX/XXXX I filled out the Fedlaon applica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Student loan</td>\n",
       "      <td>I am being contacted by a debt collector for p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Student loan</td>\n",
       "      <td>I cosigned XXXX student loans at SallieMae for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Student loan</td>\n",
       "      <td>Navient has sytematically and illegally failed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Student loan</td>\n",
       "      <td>My wife became eligible for XXXX Loan Forgiven...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Product                       Consumer complaint narrative\n",
       "0  Student loan  In XX/XX/XXXX I filled out the Fedlaon applica...\n",
       "1  Student loan  I am being contacted by a debt collector for p...\n",
       "2  Student loan  I cosigned XXXX student loans at SallieMae for...\n",
       "3  Student loan  Navient has sytematically and illegally failed...\n",
       "4  Student loan  My wife became eligible for XXXX Loan Forgiven..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Flatten, Dense\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.layers import Embedding, Dense, Dropout\n",
    "from keras import preprocessing\n",
    "\n",
    "df = pd.read_csv('Bank_complaints.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(123)\n",
    "df = df.sample(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index = range(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "product = df[\"Product\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 7 types of complaints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Student loan                   403\n",
       "Credit card                    340\n",
       "Consumer Loan                  320\n",
       "Mortgage                       265\n",
       "Bank account or service        241\n",
       "Credit reporting               226\n",
       "Checking or savings account    205\n",
       "Name: Product, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 2 columns):\n",
      "Product                         2000 non-null object\n",
      "Consumer complaint narrative    2000 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 31.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "complaints = df[\"Consumer complaint narrative\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Classifying bank complaints using word embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Pretraining your own embedding layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to create our own embedding. Let's start with importing an embedding layer. \n",
    "- `input_dim`: We specify the vocabulary `n_words` to be equal to 1000.\n",
    "- `output_dim`: The size of the vector space of the embedding vector (100)\n",
    "- `input_length`: This the length of the sentences, so equal to `max_sentence_length` in our example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_words = 1000\n",
    "output_dim = 100\n",
    "max_sentence_length = 200 \n",
    "\n",
    "embedding_layer = Embedding(input_dim = n_words, output_dim = 100, input_length = max_sentence_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only keep 1,000 most common words and use one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words = n_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(complaints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "complaints_encoded = tokenizer.texts_to_sequences(complaints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will turn the sequence array into an array with\n",
    "# the 30 most common words per sequence.\n",
    "seq_padded = preprocessing.sequence.pad_sequences(complaints_encoded, \n",
    "                                               maxlen=max_sentence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(product)\n",
    "list(le.classes_)\n",
    "product_cat = le.transform(product)\n",
    "product_onehot = to_categorical(product_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 7)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(product_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 200)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(seq_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(seq_padded,  \n",
    "            product_onehot, test_size=0.10, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1800, 200)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 200)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1800, 7)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 7)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 7)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_onehot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 200, 100)          100000    \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 20000)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                1000050   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 25)                1275      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 7)                 182       \n",
      "=================================================================\n",
      "Total params: 1,101,507\n",
      "Trainable params: 1,101,507\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import regularizers\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(n_words, output_dim, input_length = max_sentence_length))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu')) #input_shape=(20000,)\n",
    "model.add(Dense(25, activation='relu'))\n",
    "\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1440 samples, validate on 360 samples\n",
      "Epoch 1/50\n",
      "1440/1440 [==============================] - 1s 503us/step - loss: 1.9453 - acc: 0.1590 - val_loss: 1.9260 - val_acc: 0.1833\n",
      "Epoch 2/50\n",
      "1440/1440 [==============================] - 0s 323us/step - loss: 1.7980 - acc: 0.3104 - val_loss: 1.9043 - val_acc: 0.2056\n",
      "Epoch 3/50\n",
      "1440/1440 [==============================] - 0s 320us/step - loss: 1.5779 - acc: 0.4819 - val_loss: 1.8629 - val_acc: 0.2028\n",
      "Epoch 4/50\n",
      "1440/1440 [==============================] - 0s 313us/step - loss: 1.3177 - acc: 0.6194 - val_loss: 1.8282 - val_acc: 0.3000\n",
      "Epoch 5/50\n",
      "1440/1440 [==============================] - 0s 311us/step - loss: 1.0319 - acc: 0.7271 - val_loss: 1.8664 - val_acc: 0.2000\n",
      "Epoch 6/50\n",
      "1440/1440 [==============================] - 0s 319us/step - loss: 0.8189 - acc: 0.8014 - val_loss: 1.7896 - val_acc: 0.3250\n",
      "Epoch 7/50\n",
      "1440/1440 [==============================] - 0s 331us/step - loss: 0.5985 - acc: 0.8826 - val_loss: 1.7172 - val_acc: 0.3472\n",
      "Epoch 8/50\n",
      "1440/1440 [==============================] - 0s 318us/step - loss: 0.4696 - acc: 0.9042 - val_loss: 1.6666 - val_acc: 0.3528\n",
      "Epoch 9/50\n",
      "1440/1440 [==============================] - 0s 328us/step - loss: 0.3242 - acc: 0.9569 - val_loss: 1.7966 - val_acc: 0.3361\n",
      "Epoch 10/50\n",
      "1440/1440 [==============================] - 0s 318us/step - loss: 0.2599 - acc: 0.9604 - val_loss: 1.6009 - val_acc: 0.4056\n",
      "Epoch 11/50\n",
      "1440/1440 [==============================] - 0s 317us/step - loss: 0.1699 - acc: 0.9882 - val_loss: 1.6378 - val_acc: 0.3806\n",
      "Epoch 12/50\n",
      "1440/1440 [==============================] - 0s 310us/step - loss: 0.1350 - acc: 0.9861 - val_loss: 1.5618 - val_acc: 0.3917\n",
      "Epoch 13/50\n",
      "1440/1440 [==============================] - 0s 319us/step - loss: 0.0971 - acc: 0.9910 - val_loss: 1.7078 - val_acc: 0.3694\n",
      "Epoch 14/50\n",
      "1440/1440 [==============================] - 0s 318us/step - loss: 0.0681 - acc: 0.9972 - val_loss: 1.6719 - val_acc: 0.4000\n",
      "Epoch 15/50\n",
      "1440/1440 [==============================] - 0s 317us/step - loss: 0.0468 - acc: 0.9972 - val_loss: 1.8251 - val_acc: 0.3861\n",
      "Epoch 16/50\n",
      "1440/1440 [==============================] - 0s 333us/step - loss: 0.0368 - acc: 0.9979 - val_loss: 1.6920 - val_acc: 0.4222\n",
      "Epoch 17/50\n",
      "1440/1440 [==============================] - 0s 332us/step - loss: 0.0263 - acc: 0.9979 - val_loss: 2.1581 - val_acc: 0.3333\n",
      "Epoch 18/50\n",
      "1440/1440 [==============================] - 0s 325us/step - loss: 0.0212 - acc: 0.9993 - val_loss: 1.7937 - val_acc: 0.4139\n",
      "Epoch 19/50\n",
      "1440/1440 [==============================] - 0s 318us/step - loss: 0.0116 - acc: 1.0000 - val_loss: 1.9481 - val_acc: 0.3750\n",
      "Epoch 20/50\n",
      "1440/1440 [==============================] - 0s 335us/step - loss: 0.0090 - acc: 1.0000 - val_loss: 2.2160 - val_acc: 0.3472\n",
      "Epoch 21/50\n",
      "1440/1440 [==============================] - 0s 325us/step - loss: 0.0095 - acc: 0.9993 - val_loss: 2.0671 - val_acc: 0.3611\n",
      "Epoch 22/50\n",
      "1440/1440 [==============================] - 1s 357us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 1.8871 - val_acc: 0.4056\n",
      "Epoch 23/50\n",
      "1440/1440 [==============================] - 0s 330us/step - loss: 0.0032 - acc: 1.0000 - val_loss: 2.3178 - val_acc: 0.3722\n",
      "Epoch 24/50\n",
      "1440/1440 [==============================] - 0s 331us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 2.0779 - val_acc: 0.4028\n",
      "Epoch 25/50\n",
      "1440/1440 [==============================] - 0s 327us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 2.1249 - val_acc: 0.3833\n",
      "Epoch 26/50\n",
      "1440/1440 [==============================] - 0s 312us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 2.1257 - val_acc: 0.4056\n",
      "Epoch 27/50\n",
      "1440/1440 [==============================] - 0s 322us/step - loss: 8.7544e-04 - acc: 1.0000 - val_loss: 2.1591 - val_acc: 0.4194\n",
      "Epoch 28/50\n",
      "1440/1440 [==============================] - 0s 317us/step - loss: 6.2889e-04 - acc: 1.0000 - val_loss: 2.1589 - val_acc: 0.4222\n",
      "Epoch 29/50\n",
      "1440/1440 [==============================] - 0s 328us/step - loss: 4.4159e-04 - acc: 1.0000 - val_loss: 2.2454 - val_acc: 0.4222\n",
      "Epoch 30/50\n",
      "1440/1440 [==============================] - 0s 327us/step - loss: 2.9587e-04 - acc: 1.0000 - val_loss: 2.2817 - val_acc: 0.4306\n",
      "Epoch 31/50\n",
      "1440/1440 [==============================] - 0s 308us/step - loss: 2.3049e-04 - acc: 1.0000 - val_loss: 2.2663 - val_acc: 0.4333\n",
      "Epoch 32/50\n",
      "1440/1440 [==============================] - 0s 310us/step - loss: 1.5933e-04 - acc: 1.0000 - val_loss: 2.3488 - val_acc: 0.4333\n",
      "Epoch 33/50\n",
      "1440/1440 [==============================] - 0s 327us/step - loss: 1.1928e-04 - acc: 1.0000 - val_loss: 2.4994 - val_acc: 0.4194\n",
      "Epoch 34/50\n",
      "1440/1440 [==============================] - 0s 309us/step - loss: 9.3724e-05 - acc: 1.0000 - val_loss: 2.4594 - val_acc: 0.4250\n",
      "Epoch 35/50\n",
      "1440/1440 [==============================] - 0s 322us/step - loss: 5.6262e-05 - acc: 1.0000 - val_loss: 2.6524 - val_acc: 0.3889\n",
      "Epoch 36/50\n",
      "1440/1440 [==============================] - 0s 317us/step - loss: 5.5202e-05 - acc: 1.0000 - val_loss: 2.5435 - val_acc: 0.4361\n",
      "Epoch 37/50\n",
      "1440/1440 [==============================] - 0s 304us/step - loss: 2.8941e-05 - acc: 1.0000 - val_loss: 2.6105 - val_acc: 0.4222\n",
      "Epoch 38/50\n",
      "1440/1440 [==============================] - 0s 308us/step - loss: 2.1145e-05 - acc: 1.0000 - val_loss: 2.6447 - val_acc: 0.4278\n",
      "Epoch 39/50\n",
      "1440/1440 [==============================] - 0s 311us/step - loss: 1.7463e-05 - acc: 1.0000 - val_loss: 2.6931 - val_acc: 0.4250\n",
      "Epoch 40/50\n",
      "1440/1440 [==============================] - 0s 324us/step - loss: 1.2074e-05 - acc: 1.0000 - val_loss: 2.7270 - val_acc: 0.4278\n",
      "Epoch 41/50\n",
      "1440/1440 [==============================] - 0s 318us/step - loss: 8.8691e-06 - acc: 1.0000 - val_loss: 2.7841 - val_acc: 0.4306\n",
      "Epoch 42/50\n",
      "1440/1440 [==============================] - 0s 312us/step - loss: 6.4073e-06 - acc: 1.0000 - val_loss: 2.8401 - val_acc: 0.4250\n",
      "Epoch 43/50\n",
      "1440/1440 [==============================] - 0s 309us/step - loss: 5.0440e-06 - acc: 1.0000 - val_loss: 2.8591 - val_acc: 0.4361\n",
      "Epoch 44/50\n",
      "1440/1440 [==============================] - 0s 316us/step - loss: 3.6985e-06 - acc: 1.0000 - val_loss: 2.8845 - val_acc: 0.4306\n",
      "Epoch 45/50\n",
      "1440/1440 [==============================] - 0s 309us/step - loss: 2.8342e-06 - acc: 1.0000 - val_loss: 3.0097 - val_acc: 0.4278\n",
      "Epoch 46/50\n",
      "1440/1440 [==============================] - 0s 321us/step - loss: 2.1962e-06 - acc: 1.0000 - val_loss: 2.9442 - val_acc: 0.4306\n",
      "Epoch 47/50\n",
      "1440/1440 [==============================] - 0s 319us/step - loss: 1.6713e-06 - acc: 1.0000 - val_loss: 2.9993 - val_acc: 0.4278\n",
      "Epoch 48/50\n",
      "1440/1440 [==============================] - 0s 320us/step - loss: 1.3256e-06 - acc: 1.0000 - val_loss: 3.1252 - val_acc: 0.4278\n",
      "Epoch 49/50\n",
      "1440/1440 [==============================] - 0s 312us/step - loss: 1.0699e-06 - acc: 1.0000 - val_loss: 3.1368 - val_acc: 0.4222\n",
      "Epoch 50/50\n",
      "1440/1440 [==============================] - 0s 319us/step - loss: 8.1725e-07 - acc: 1.0000 - val_loss: 3.1515 - val_acc: 0.4278\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs=50, batch_size=256, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(x_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0200108528137206"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.385"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Using dropout regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 200, 100)          100000    \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 20000)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 50)                1000050   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 25)                1275      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 7)                 182       \n",
      "=================================================================\n",
      "Total params: 1,101,507\n",
      "Trainable params: 1,101,507\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "Epoch 1/50\n",
      "1440/1440 [==============================] - 1s 529us/step - loss: 1.9869 - acc: 0.1597 - val_loss: 1.9266 - val_acc: 0.2083\n",
      "Epoch 2/50\n",
      "1440/1440 [==============================] - 0s 328us/step - loss: 1.8610 - acc: 0.2764 - val_loss: 1.9010 - val_acc: 0.2417\n",
      "Epoch 3/50\n",
      "1440/1440 [==============================] - 0s 331us/step - loss: 1.7462 - acc: 0.3431 - val_loss: 1.8856 - val_acc: 0.2417\n",
      "Epoch 4/50\n",
      "1440/1440 [==============================] - 0s 317us/step - loss: 1.6030 - acc: 0.3986 - val_loss: 1.8545 - val_acc: 0.3000\n",
      "Epoch 5/50\n",
      "1440/1440 [==============================] - 0s 320us/step - loss: 1.4330 - acc: 0.4840 - val_loss: 1.7966 - val_acc: 0.3000\n",
      "Epoch 6/50\n",
      "1440/1440 [==============================] - 0s 327us/step - loss: 1.2975 - acc: 0.5451 - val_loss: 1.7686 - val_acc: 0.3111\n",
      "Epoch 7/50\n",
      "1440/1440 [==============================] - 0s 330us/step - loss: 1.1614 - acc: 0.5875 - val_loss: 1.7226 - val_acc: 0.3250\n",
      "Epoch 8/50\n",
      "1440/1440 [==============================] - 0s 333us/step - loss: 1.0185 - acc: 0.6562 - val_loss: 1.6590 - val_acc: 0.3833\n",
      "Epoch 9/50\n",
      "1440/1440 [==============================] - 1s 354us/step - loss: 0.8893 - acc: 0.7083 - val_loss: 1.6671 - val_acc: 0.3611\n",
      "Epoch 10/50\n",
      "1440/1440 [==============================] - 0s 327us/step - loss: 0.8137 - acc: 0.7326 - val_loss: 1.6136 - val_acc: 0.3917\n",
      "Epoch 11/50\n",
      "1440/1440 [==============================] - 0s 319us/step - loss: 0.6658 - acc: 0.7979 - val_loss: 1.5610 - val_acc: 0.4444\n",
      "Epoch 12/50\n",
      "1440/1440 [==============================] - 0s 332us/step - loss: 0.5820 - acc: 0.8257 - val_loss: 1.5750 - val_acc: 0.4083\n",
      "Epoch 13/50\n",
      "1440/1440 [==============================] - 0s 336us/step - loss: 0.4962 - acc: 0.8618 - val_loss: 1.6011 - val_acc: 0.3861\n",
      "Epoch 14/50\n",
      "1440/1440 [==============================] - 0s 343us/step - loss: 0.4279 - acc: 0.8813 - val_loss: 1.5738 - val_acc: 0.4278\n",
      "Epoch 15/50\n",
      "1440/1440 [==============================] - 0s 328us/step - loss: 0.3649 - acc: 0.9097 - val_loss: 1.5633 - val_acc: 0.4306\n",
      "Epoch 16/50\n",
      "1440/1440 [==============================] - 0s 337us/step - loss: 0.3372 - acc: 0.9236 - val_loss: 1.6072 - val_acc: 0.4417\n",
      "Epoch 17/50\n",
      "1440/1440 [==============================] - 0s 336us/step - loss: 0.2582 - acc: 0.9431 - val_loss: 1.6051 - val_acc: 0.4528\n",
      "Epoch 18/50\n",
      "1440/1440 [==============================] - 0s 333us/step - loss: 0.2334 - acc: 0.9549 - val_loss: 1.5912 - val_acc: 0.4861\n",
      "Epoch 19/50\n",
      "1440/1440 [==============================] - 0s 331us/step - loss: 0.1974 - acc: 0.9590 - val_loss: 1.6803 - val_acc: 0.4528\n",
      "Epoch 20/50\n",
      "1440/1440 [==============================] - 1s 356us/step - loss: 0.1830 - acc: 0.9646 - val_loss: 1.6637 - val_acc: 0.4889\n",
      "Epoch 21/50\n",
      "1440/1440 [==============================] - 0s 329us/step - loss: 0.1608 - acc: 0.9701 - val_loss: 1.7470 - val_acc: 0.4528\n",
      "Epoch 22/50\n",
      "1440/1440 [==============================] - 0s 344us/step - loss: 0.1365 - acc: 0.9681 - val_loss: 1.8174 - val_acc: 0.4472\n",
      "Epoch 23/50\n",
      "1440/1440 [==============================] - 0s 333us/step - loss: 0.1251 - acc: 0.9757 - val_loss: 1.7847 - val_acc: 0.4528\n",
      "Epoch 24/50\n",
      "1440/1440 [==============================] - 0s 321us/step - loss: 0.1076 - acc: 0.9785 - val_loss: 1.8237 - val_acc: 0.4528\n",
      "Epoch 25/50\n",
      "1440/1440 [==============================] - 0s 330us/step - loss: 0.1033 - acc: 0.9764 - val_loss: 1.7954 - val_acc: 0.4778\n",
      "Epoch 26/50\n",
      "1440/1440 [==============================] - 0s 325us/step - loss: 0.0861 - acc: 0.9826 - val_loss: 1.8256 - val_acc: 0.4528\n",
      "Epoch 27/50\n",
      "1440/1440 [==============================] - 0s 337us/step - loss: 0.0799 - acc: 0.9806 - val_loss: 1.8710 - val_acc: 0.4500\n",
      "Epoch 28/50\n",
      "1440/1440 [==============================] - 0s 341us/step - loss: 0.0814 - acc: 0.9819 - val_loss: 2.0455 - val_acc: 0.4528\n",
      "Epoch 29/50\n",
      "1440/1440 [==============================] - 0s 327us/step - loss: 0.0729 - acc: 0.9875 - val_loss: 2.0156 - val_acc: 0.4583\n",
      "Epoch 30/50\n",
      "1440/1440 [==============================] - 0s 328us/step - loss: 0.0614 - acc: 0.9889 - val_loss: 2.0228 - val_acc: 0.4611\n",
      "Epoch 31/50\n",
      "1440/1440 [==============================] - 0s 324us/step - loss: 0.0566 - acc: 0.9903 - val_loss: 1.9726 - val_acc: 0.4361\n",
      "Epoch 32/50\n",
      "1440/1440 [==============================] - 0s 343us/step - loss: 0.0596 - acc: 0.9861 - val_loss: 2.1038 - val_acc: 0.4500\n",
      "Epoch 33/50\n",
      "1440/1440 [==============================] - 0s 329us/step - loss: 0.0563 - acc: 0.9861 - val_loss: 2.0880 - val_acc: 0.4500\n",
      "Epoch 34/50\n",
      "1440/1440 [==============================] - 0s 340us/step - loss: 0.0439 - acc: 0.9924 - val_loss: 2.1711 - val_acc: 0.4611\n",
      "Epoch 35/50\n",
      "1440/1440 [==============================] - 0s 327us/step - loss: 0.0344 - acc: 0.9958 - val_loss: 2.1740 - val_acc: 0.4556\n",
      "Epoch 36/50\n",
      "1440/1440 [==============================] - 0s 331us/step - loss: 0.0327 - acc: 0.9924 - val_loss: 2.2032 - val_acc: 0.4639\n",
      "Epoch 37/50\n",
      "1440/1440 [==============================] - 0s 328us/step - loss: 0.0476 - acc: 0.9889 - val_loss: 2.3115 - val_acc: 0.4389\n",
      "Epoch 38/50\n",
      "1440/1440 [==============================] - 0s 330us/step - loss: 0.0364 - acc: 0.9917 - val_loss: 2.1701 - val_acc: 0.4750\n",
      "Epoch 39/50\n",
      "1440/1440 [==============================] - 0s 318us/step - loss: 0.0309 - acc: 0.9951 - val_loss: 2.3273 - val_acc: 0.4694\n",
      "Epoch 40/50\n",
      "1440/1440 [==============================] - 0s 326us/step - loss: 0.0335 - acc: 0.9937 - val_loss: 2.3952 - val_acc: 0.4694\n",
      "Epoch 41/50\n",
      "1440/1440 [==============================] - 0s 333us/step - loss: 0.0307 - acc: 0.9944 - val_loss: 2.4607 - val_acc: 0.4583\n",
      "Epoch 42/50\n",
      "1440/1440 [==============================] - 0s 317us/step - loss: 0.0328 - acc: 0.9903 - val_loss: 2.4670 - val_acc: 0.4556\n",
      "Epoch 43/50\n",
      "1440/1440 [==============================] - 0s 323us/step - loss: 0.0266 - acc: 0.9944 - val_loss: 2.4829 - val_acc: 0.4389\n",
      "Epoch 44/50\n",
      "1440/1440 [==============================] - 1s 353us/step - loss: 0.0256 - acc: 0.9931 - val_loss: 2.6183 - val_acc: 0.4722\n",
      "Epoch 45/50\n",
      "1440/1440 [==============================] - 0s 331us/step - loss: 0.0209 - acc: 0.9965 - val_loss: 2.6286 - val_acc: 0.4639\n",
      "Epoch 46/50\n",
      "1440/1440 [==============================] - 0s 325us/step - loss: 0.0277 - acc: 0.9896 - val_loss: 2.6607 - val_acc: 0.4583\n",
      "Epoch 47/50\n",
      "1440/1440 [==============================] - 0s 342us/step - loss: 0.0217 - acc: 0.9958 - val_loss: 2.7553 - val_acc: 0.4361\n",
      "Epoch 48/50\n",
      "1440/1440 [==============================] - 1s 363us/step - loss: 0.0238 - acc: 0.9951 - val_loss: 2.7570 - val_acc: 0.4389\n",
      "Epoch 49/50\n",
      "1440/1440 [==============================] - 0s 340us/step - loss: 0.0202 - acc: 0.9965 - val_loss: 2.6504 - val_acc: 0.4306\n",
      "Epoch 50/50\n",
      "1440/1440 [==============================] - 0s 333us/step - loss: 0.0203 - acc: 0.9951 - val_loss: 2.6215 - val_acc: 0.4611\n"
     ]
    }
   ],
   "source": [
    "from keras import regularizers\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(n_words, output_dim, input_length = max_sentence_length))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(25, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])\n",
    "model.summary()\n",
    "history = model.fit(x_train, y_train, epochs=50, batch_size=256, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(x_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.653766975402832"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 A pre-trained embedding layer with a deeper network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_index = {}\n",
    "embedding_file = open('glove.6B.100d.txt')\n",
    "for line in embedding_file:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embed_index[word] = coefs\n",
    "embedding_file.close()\n",
    "len(embed_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(complaints)\n",
    "n_words = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "complaints_encoded = tokenizer.texts_to_sequences(complaints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a weight matrix for words in training docs\n",
    "embedding_matrix = np.zeros((n_words, 100))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "\tembedding_vector = embed_index.get(word)\n",
    "\tif embedding_vector is not None:\n",
    "\t\tembedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10555, 100)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sentence_length = 200\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "padded_complaints= pad_sequences(complaints_encoded, maxlen=max_sentence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 200, 100)          1055500   \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 20000)             0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 50)                1000050   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 25)                1275      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 7)                 182       \n",
      "=================================================================\n",
      "Total params: 2,057,007\n",
      "Trainable params: 1,001,507\n",
      "Non-trainable params: 1,055,500\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "Epoch 1/100\n",
      "1440/1440 [==============================] - 1s 664us/step - loss: 3.9110 - acc: 0.1556 - val_loss: 1.9560 - val_acc: 0.1667\n",
      "Epoch 2/100\n",
      "1440/1440 [==============================] - 0s 270us/step - loss: 2.0260 - acc: 0.1660 - val_loss: 1.9620 - val_acc: 0.2083\n",
      "Epoch 3/100\n",
      "1440/1440 [==============================] - 0s 272us/step - loss: 1.9386 - acc: 0.1785 - val_loss: 1.9540 - val_acc: 0.1583\n",
      "Epoch 4/100\n",
      "1440/1440 [==============================] - 0s 282us/step - loss: 1.9567 - acc: 0.2049 - val_loss: 1.9180 - val_acc: 0.2194\n",
      "Epoch 5/100\n",
      "1440/1440 [==============================] - 0s 286us/step - loss: 1.8867 - acc: 0.2167 - val_loss: 1.9264 - val_acc: 0.1722\n",
      "Epoch 6/100\n",
      "1440/1440 [==============================] - 0s 273us/step - loss: 1.8926 - acc: 0.2069 - val_loss: 1.9326 - val_acc: 0.1556\n",
      "Epoch 7/100\n",
      "1440/1440 [==============================] - 0s 277us/step - loss: 1.9350 - acc: 0.2056 - val_loss: 1.9145 - val_acc: 0.1528\n",
      "Epoch 8/100\n",
      "1440/1440 [==============================] - 0s 272us/step - loss: 1.8461 - acc: 0.2243 - val_loss: 1.8885 - val_acc: 0.1778\n",
      "Epoch 9/100\n",
      "1440/1440 [==============================] - 0s 276us/step - loss: 1.8034 - acc: 0.2674 - val_loss: 1.8882 - val_acc: 0.1944\n",
      "Epoch 10/100\n",
      "1440/1440 [==============================] - 0s 285us/step - loss: 1.8496 - acc: 0.2743 - val_loss: 2.1572 - val_acc: 0.1528\n",
      "Epoch 11/100\n",
      "1440/1440 [==============================] - 0s 269us/step - loss: 1.9052 - acc: 0.2438 - val_loss: 1.8860 - val_acc: 0.2361\n",
      "Epoch 12/100\n",
      "1440/1440 [==============================] - 0s 264us/step - loss: 1.7538 - acc: 0.2889 - val_loss: 1.8547 - val_acc: 0.2583\n",
      "Epoch 13/100\n",
      "1440/1440 [==============================] - 0s 297us/step - loss: 1.7793 - acc: 0.2889 - val_loss: 1.8833 - val_acc: 0.2056\n",
      "Epoch 14/100\n",
      "1440/1440 [==============================] - 0s 279us/step - loss: 1.6884 - acc: 0.3215 - val_loss: 1.8418 - val_acc: 0.2667\n",
      "Epoch 15/100\n",
      "1440/1440 [==============================] - 0s 267us/step - loss: 1.6757 - acc: 0.3111 - val_loss: 1.9494 - val_acc: 0.1472\n",
      "Epoch 16/100\n",
      "1440/1440 [==============================] - 0s 273us/step - loss: 1.6905 - acc: 0.3271 - val_loss: 1.8857 - val_acc: 0.1972\n",
      "Epoch 17/100\n",
      "1440/1440 [==============================] - 0s 277us/step - loss: 1.6591 - acc: 0.3354 - val_loss: 1.8265 - val_acc: 0.2611\n",
      "Epoch 18/100\n",
      "1440/1440 [==============================] - 0s 270us/step - loss: 1.5902 - acc: 0.3694 - val_loss: 1.8351 - val_acc: 0.2333\n",
      "Epoch 19/100\n",
      "1440/1440 [==============================] - 0s 268us/step - loss: 1.5735 - acc: 0.3792 - val_loss: 1.8450 - val_acc: 0.2278\n",
      "Epoch 20/100\n",
      "1440/1440 [==============================] - 0s 290us/step - loss: 1.5806 - acc: 0.3993 - val_loss: 1.8231 - val_acc: 0.2667\n",
      "Epoch 21/100\n",
      "1440/1440 [==============================] - 0s 265us/step - loss: 1.4378 - acc: 0.4292 - val_loss: 1.8835 - val_acc: 0.2778\n",
      "Epoch 22/100\n",
      "1440/1440 [==============================] - 0s 271us/step - loss: 1.4881 - acc: 0.4118 - val_loss: 1.8899 - val_acc: 0.2917\n",
      "Epoch 23/100\n",
      "1440/1440 [==============================] - 0s 266us/step - loss: 1.4116 - acc: 0.4590 - val_loss: 1.8581 - val_acc: 0.2528\n",
      "Epoch 24/100\n",
      "1440/1440 [==============================] - 0s 273us/step - loss: 1.3337 - acc: 0.4917 - val_loss: 1.9992 - val_acc: 0.1722\n",
      "Epoch 25/100\n",
      "1440/1440 [==============================] - 0s 278us/step - loss: 1.3525 - acc: 0.4722 - val_loss: 1.7802 - val_acc: 0.2972\n",
      "Epoch 26/100\n",
      "1440/1440 [==============================] - 0s 273us/step - loss: 1.2817 - acc: 0.4938 - val_loss: 1.9020 - val_acc: 0.2139\n",
      "Epoch 27/100\n",
      "1440/1440 [==============================] - 0s 279us/step - loss: 1.2777 - acc: 0.4819 - val_loss: 1.8376 - val_acc: 0.2750\n",
      "Epoch 28/100\n",
      "1440/1440 [==============================] - 0s 275us/step - loss: 1.2112 - acc: 0.5257 - val_loss: 2.0897 - val_acc: 0.3028\n",
      "Epoch 29/100\n",
      "1440/1440 [==============================] - 0s 269us/step - loss: 1.3777 - acc: 0.5021 - val_loss: 1.8844 - val_acc: 0.2417\n",
      "Epoch 30/100\n",
      "1440/1440 [==============================] - 0s 268us/step - loss: 1.1727 - acc: 0.5556 - val_loss: 1.8430 - val_acc: 0.2583\n",
      "Epoch 31/100\n",
      "1440/1440 [==============================] - 0s 266us/step - loss: 1.0623 - acc: 0.6097 - val_loss: 1.8569 - val_acc: 0.2972\n",
      "Epoch 32/100\n",
      "1440/1440 [==============================] - 0s 273us/step - loss: 1.0473 - acc: 0.6007 - val_loss: 1.7966 - val_acc: 0.2722\n",
      "Epoch 33/100\n",
      "1440/1440 [==============================] - 0s 262us/step - loss: 1.0901 - acc: 0.5806 - val_loss: 1.9627 - val_acc: 0.2083\n",
      "Epoch 34/100\n",
      "1440/1440 [==============================] - 0s 267us/step - loss: 1.0266 - acc: 0.6028 - val_loss: 1.8133 - val_acc: 0.3056\n",
      "Epoch 35/100\n",
      "1440/1440 [==============================] - 0s 273us/step - loss: 0.9848 - acc: 0.6340 - val_loss: 1.9957 - val_acc: 0.2944\n",
      "Epoch 36/100\n",
      "1440/1440 [==============================] - 0s 268us/step - loss: 0.9362 - acc: 0.6444 - val_loss: 2.1962 - val_acc: 0.2750\n",
      "Epoch 37/100\n",
      "1440/1440 [==============================] - 0s 263us/step - loss: 0.9886 - acc: 0.6382 - val_loss: 1.8980 - val_acc: 0.3389\n",
      "Epoch 38/100\n",
      "1440/1440 [==============================] - 0s 273us/step - loss: 0.8317 - acc: 0.7021 - val_loss: 1.9429 - val_acc: 0.3222\n",
      "Epoch 39/100\n",
      "1440/1440 [==============================] - 0s 264us/step - loss: 0.9322 - acc: 0.6542 - val_loss: 1.8254 - val_acc: 0.3000\n",
      "Epoch 40/100\n",
      "1440/1440 [==============================] - 0s 263us/step - loss: 0.8155 - acc: 0.7097 - val_loss: 1.9303 - val_acc: 0.3111\n",
      "Epoch 41/100\n",
      "1440/1440 [==============================] - 0s 264us/step - loss: 0.8500 - acc: 0.6854 - val_loss: 2.0833 - val_acc: 0.2500\n",
      "Epoch 42/100\n",
      "1440/1440 [==============================] - 0s 263us/step - loss: 1.1366 - acc: 0.6035 - val_loss: 1.8395 - val_acc: 0.3083\n",
      "Epoch 43/100\n",
      "1440/1440 [==============================] - 0s 286us/step - loss: 0.7572 - acc: 0.7250 - val_loss: 1.8489 - val_acc: 0.3222\n",
      "Epoch 44/100\n",
      "1440/1440 [==============================] - 0s 270us/step - loss: 0.7123 - acc: 0.7597 - val_loss: 1.8724 - val_acc: 0.3139\n",
      "Epoch 45/100\n",
      "1440/1440 [==============================] - 0s 259us/step - loss: 0.7009 - acc: 0.7639 - val_loss: 2.0835 - val_acc: 0.3361\n",
      "Epoch 46/100\n",
      "1440/1440 [==============================] - 0s 263us/step - loss: 0.7980 - acc: 0.7063 - val_loss: 2.0855 - val_acc: 0.3222\n",
      "Epoch 47/100\n",
      "1440/1440 [==============================] - 0s 272us/step - loss: 0.7164 - acc: 0.7458 - val_loss: 2.1799 - val_acc: 0.3056\n",
      "Epoch 48/100\n",
      "1440/1440 [==============================] - 0s 278us/step - loss: 0.7189 - acc: 0.7479 - val_loss: 2.0518 - val_acc: 0.3306\n",
      "Epoch 49/100\n",
      "1440/1440 [==============================] - 0s 275us/step - loss: 0.6874 - acc: 0.7549 - val_loss: 2.1563 - val_acc: 0.3083\n",
      "Epoch 50/100\n",
      "1440/1440 [==============================] - 0s 270us/step - loss: 0.7538 - acc: 0.7257 - val_loss: 1.9862 - val_acc: 0.3333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/100\n",
      "1440/1440 [==============================] - 0s 280us/step - loss: 0.6505 - acc: 0.7778 - val_loss: 1.9596 - val_acc: 0.2750\n",
      "Epoch 52/100\n",
      "1440/1440 [==============================] - 0s 269us/step - loss: 0.6710 - acc: 0.7667 - val_loss: 1.9346 - val_acc: 0.3083\n",
      "Epoch 53/100\n",
      "1440/1440 [==============================] - 0s 265us/step - loss: 0.6784 - acc: 0.7632 - val_loss: 1.9507 - val_acc: 0.3000\n",
      "Epoch 54/100\n",
      "1440/1440 [==============================] - 0s 270us/step - loss: 0.6114 - acc: 0.8000 - val_loss: 2.1946 - val_acc: 0.3111\n",
      "Epoch 55/100\n",
      "1440/1440 [==============================] - 0s 271us/step - loss: 0.6455 - acc: 0.7688 - val_loss: 2.1086 - val_acc: 0.3028\n",
      "Epoch 56/100\n",
      "1440/1440 [==============================] - 0s 269us/step - loss: 0.6106 - acc: 0.7847 - val_loss: 2.0042 - val_acc: 0.3306\n",
      "Epoch 57/100\n",
      "1440/1440 [==============================] - 0s 267us/step - loss: 0.6192 - acc: 0.7882 - val_loss: 2.2606 - val_acc: 0.2806\n",
      "Epoch 58/100\n",
      "1440/1440 [==============================] - 0s 274us/step - loss: 0.6169 - acc: 0.7812 - val_loss: 2.0981 - val_acc: 0.2806\n",
      "Epoch 59/100\n",
      "1440/1440 [==============================] - 0s 274us/step - loss: 0.5685 - acc: 0.8069 - val_loss: 2.0426 - val_acc: 0.2944\n",
      "Epoch 60/100\n",
      "1440/1440 [==============================] - 0s 271us/step - loss: 0.5404 - acc: 0.8181 - val_loss: 2.2137 - val_acc: 0.2889\n",
      "Epoch 61/100\n",
      "1440/1440 [==============================] - 0s 261us/step - loss: 0.5576 - acc: 0.8083 - val_loss: 2.2699 - val_acc: 0.2750\n",
      "Epoch 62/100\n",
      "1440/1440 [==============================] - 0s 270us/step - loss: 0.5775 - acc: 0.8090 - val_loss: 2.0566 - val_acc: 0.3028\n",
      "Epoch 63/100\n",
      "1440/1440 [==============================] - 0s 264us/step - loss: 0.7001 - acc: 0.7653 - val_loss: 2.4349 - val_acc: 0.2583\n",
      "Epoch 64/100\n",
      "1440/1440 [==============================] - 0s 266us/step - loss: 0.5890 - acc: 0.7986 - val_loss: 2.0757 - val_acc: 0.3000\n",
      "Epoch 65/100\n",
      "1440/1440 [==============================] - 0s 273us/step - loss: 0.4912 - acc: 0.8368 - val_loss: 2.2640 - val_acc: 0.3278\n",
      "Epoch 66/100\n",
      "1440/1440 [==============================] - 0s 290us/step - loss: 0.5524 - acc: 0.8069 - val_loss: 2.1645 - val_acc: 0.2917\n",
      "Epoch 67/100\n",
      "1440/1440 [==============================] - 0s 276us/step - loss: 0.4838 - acc: 0.8417 - val_loss: 2.3344 - val_acc: 0.3111\n",
      "Epoch 68/100\n",
      "1440/1440 [==============================] - 0s 261us/step - loss: 0.5754 - acc: 0.7993 - val_loss: 2.2318 - val_acc: 0.3056\n",
      "Epoch 69/100\n",
      "1440/1440 [==============================] - 0s 271us/step - loss: 0.4901 - acc: 0.8264 - val_loss: 2.6179 - val_acc: 0.3056\n",
      "Epoch 70/100\n",
      "1440/1440 [==============================] - 0s 267us/step - loss: 0.5615 - acc: 0.7958 - val_loss: 2.3039 - val_acc: 0.2806\n",
      "Epoch 71/100\n",
      "1440/1440 [==============================] - 0s 271us/step - loss: 0.4742 - acc: 0.8319 - val_loss: 2.3202 - val_acc: 0.3111\n",
      "Epoch 72/100\n",
      "1440/1440 [==============================] - 0s 265us/step - loss: 0.5036 - acc: 0.8243 - val_loss: 2.1132 - val_acc: 0.3000\n",
      "Epoch 73/100\n",
      "1440/1440 [==============================] - 0s 272us/step - loss: 0.4577 - acc: 0.8514 - val_loss: 2.3782 - val_acc: 0.3028\n",
      "Epoch 74/100\n",
      "1440/1440 [==============================] - 0s 284us/step - loss: 0.4581 - acc: 0.8437 - val_loss: 2.3637 - val_acc: 0.3111\n",
      "Epoch 75/100\n",
      "1440/1440 [==============================] - 0s 272us/step - loss: 0.4466 - acc: 0.8549 - val_loss: 2.4417 - val_acc: 0.3167\n",
      "Epoch 76/100\n",
      "1440/1440 [==============================] - 0s 272us/step - loss: 0.4630 - acc: 0.8451 - val_loss: 2.5608 - val_acc: 0.2694\n",
      "Epoch 77/100\n",
      "1440/1440 [==============================] - 0s 264us/step - loss: 0.4323 - acc: 0.8583 - val_loss: 2.3767 - val_acc: 0.3111\n",
      "Epoch 78/100\n",
      "1440/1440 [==============================] - 0s 259us/step - loss: 0.4245 - acc: 0.8632 - val_loss: 2.4573 - val_acc: 0.3167\n",
      "Epoch 79/100\n",
      "1440/1440 [==============================] - 0s 278us/step - loss: 0.4426 - acc: 0.8563 - val_loss: 2.3679 - val_acc: 0.3028\n",
      "Epoch 80/100\n",
      "1440/1440 [==============================] - 0s 263us/step - loss: 0.4530 - acc: 0.8507 - val_loss: 2.6266 - val_acc: 0.2972\n",
      "Epoch 81/100\n",
      "1440/1440 [==============================] - 0s 266us/step - loss: 0.4499 - acc: 0.8493 - val_loss: 2.3634 - val_acc: 0.2694\n",
      "Epoch 82/100\n",
      "1440/1440 [==============================] - 0s 280us/step - loss: 0.4388 - acc: 0.8528 - val_loss: 2.3680 - val_acc: 0.3333\n",
      "Epoch 83/100\n",
      "1440/1440 [==============================] - 0s 267us/step - loss: 0.4797 - acc: 0.8431 - val_loss: 2.3784 - val_acc: 0.3222\n",
      "Epoch 84/100\n",
      "1440/1440 [==============================] - 0s 266us/step - loss: 0.3743 - acc: 0.8743 - val_loss: 2.6685 - val_acc: 0.3111\n",
      "Epoch 85/100\n",
      "1440/1440 [==============================] - 0s 269us/step - loss: 0.4332 - acc: 0.8542 - val_loss: 2.3590 - val_acc: 0.3194\n",
      "Epoch 86/100\n",
      "1440/1440 [==============================] - 0s 270us/step - loss: 0.4239 - acc: 0.8576 - val_loss: 2.5250 - val_acc: 0.2833\n",
      "Epoch 87/100\n",
      "1440/1440 [==============================] - 0s 272us/step - loss: 0.3646 - acc: 0.8701 - val_loss: 2.5069 - val_acc: 0.3056\n",
      "Epoch 88/100\n",
      "1440/1440 [==============================] - 0s 268us/step - loss: 0.3833 - acc: 0.8688 - val_loss: 2.5677 - val_acc: 0.3194\n",
      "Epoch 89/100\n",
      "1440/1440 [==============================] - 0s 281us/step - loss: 0.4632 - acc: 0.8479 - val_loss: 2.7943 - val_acc: 0.3056\n",
      "Epoch 90/100\n",
      "1440/1440 [==============================] - 0s 279us/step - loss: 0.3756 - acc: 0.8778 - val_loss: 2.7400 - val_acc: 0.2417\n",
      "Epoch 91/100\n",
      "1440/1440 [==============================] - 0s 262us/step - loss: 0.4717 - acc: 0.8403 - val_loss: 2.4822 - val_acc: 0.3278\n",
      "Epoch 92/100\n",
      "1440/1440 [==============================] - 0s 265us/step - loss: 0.3718 - acc: 0.8667 - val_loss: 2.5955 - val_acc: 0.3306\n",
      "Epoch 93/100\n",
      "1440/1440 [==============================] - 0s 265us/step - loss: 0.3851 - acc: 0.8743 - val_loss: 2.3319 - val_acc: 0.2917\n",
      "Epoch 94/100\n",
      "1440/1440 [==============================] - 0s 265us/step - loss: 0.4289 - acc: 0.8639 - val_loss: 2.7886 - val_acc: 0.3472\n",
      "Epoch 95/100\n",
      "1440/1440 [==============================] - 0s 260us/step - loss: 0.3677 - acc: 0.8743 - val_loss: 2.6690 - val_acc: 0.3056\n",
      "Epoch 96/100\n",
      "1440/1440 [==============================] - 0s 276us/step - loss: 0.3826 - acc: 0.8687 - val_loss: 2.5419 - val_acc: 0.2944\n",
      "Epoch 97/100\n",
      "1440/1440 [==============================] - 0s 263us/step - loss: 0.5046 - acc: 0.8410 - val_loss: 2.9607 - val_acc: 0.2667\n",
      "Epoch 98/100\n",
      "1440/1440 [==============================] - 0s 277us/step - loss: 0.3751 - acc: 0.8785 - val_loss: 2.5016 - val_acc: 0.3028\n",
      "Epoch 99/100\n",
      "1440/1440 [==============================] - 0s 267us/step - loss: 0.3304 - acc: 0.8903 - val_loss: 2.4873 - val_acc: 0.3278\n",
      "Epoch 100/100\n",
      "1440/1440 [==============================] - 0s 273us/step - loss: 0.3584 - acc: 0.8771 - val_loss: 2.6136 - val_acc: 0.3083\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Embedding(n_words, 100, weights=[embedding_matrix], input_length= 200, trainable=False))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(25, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "# compile the model\n",
    "model.compile(optimizer='RMSprop', loss='categorical_crossentropy', metrics=['acc'])\n",
    "# summarize the model\n",
    "print(model.summary())\n",
    "# fit the model\n",
    "history = model.fit(x_train, y_train, epochs=100, batch_size=256, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "loss, accuracy = model.evaluate(x_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.8106768894195557"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Classifying bank complaints using word embeddings and an RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 A naive recurrent neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, 200, 100)          100000    \n",
      "_________________________________________________________________\n",
      "simple_rnn_3 (SimpleRNN)     (None, 100)               20100     \n",
      "=================================================================\n",
      "Total params: 120,100\n",
      "Trainable params: 120,100\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, SimpleRNN\n",
    "\n",
    "n_words = 1000\n",
    "output_dim = 100\n",
    "max_sentence_length = 200 \n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim = n_words, output_dim = 100, input_length = max_sentence_length))\n",
    "model.add(SimpleRNN(100))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, 200, 100)          100000    \n",
      "_________________________________________________________________\n",
      "simple_rnn_3 (SimpleRNN)     (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 7)                 707       \n",
      "=================================================================\n",
      "Total params: 120,807\n",
      "Trainable params: 120,807\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.add(Dense(7, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1440 samples, validate on 360 samples\n",
      "Epoch 1/100\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 0.6080 - acc: 0.9375 - val_loss: 2.1563 - val_acc: 0.1667\n",
      "Epoch 2/100\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 0.5096 - acc: 0.9493 - val_loss: 2.1201 - val_acc: 0.1861\n",
      "Epoch 3/100\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 0.3177 - acc: 0.9854 - val_loss: 2.2764 - val_acc: 0.1944\n",
      "Epoch 4/100\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 0.2703 - acc: 0.9868 - val_loss: 2.2984 - val_acc: 0.2167\n",
      "Epoch 5/100\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 0.2977 - acc: 0.9701 - val_loss: 2.3413 - val_acc: 0.2000\n",
      "Epoch 6/100\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 0.1293 - acc: 0.9951 - val_loss: 2.3718 - val_acc: 0.2028\n",
      "Epoch 7/100\n",
      "1440/1440 [==============================] - 2s 2ms/step - loss: 0.0791 - acc: 0.9979 - val_loss: 2.5378 - val_acc: 0.1806\n",
      "Epoch 8/100\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 0.3063 - acc: 0.9472 - val_loss: 2.5654 - val_acc: 0.1806\n",
      "Epoch 9/100\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 0.3072 - acc: 0.9424 - val_loss: 2.4553 - val_acc: 0.2417\n",
      "Epoch 10/100\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 0.0769 - acc: 0.9986 - val_loss: 2.5092 - val_acc: 0.2000\n",
      "Epoch 11/100\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 0.0436 - acc: 0.9986 - val_loss: 2.5468 - val_acc: 0.2167\n",
      "Epoch 12/100\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 0.0276 - acc: 1.0000 - val_loss: 2.6447 - val_acc: 0.2167\n",
      "Epoch 13/100\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 0.0183 - acc: 1.0000 - val_loss: 2.7384 - val_acc: 0.2306\n",
      "Epoch 14/100\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 0.0576 - acc: 0.9903 - val_loss: 2.8421 - val_acc: 0.2028\n",
      "Epoch 15/100\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 0.0156 - acc: 0.9993 - val_loss: 2.8800 - val_acc: 0.2194\n",
      "Epoch 16/100\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 0.0089 - acc: 1.0000 - val_loss: 2.9230 - val_acc: 0.2250\n",
      "Epoch 17/100\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 0.0060 - acc: 1.0000 - val_loss: 3.0163 - val_acc: 0.2194\n",
      "Epoch 18/100\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 0.0043 - acc: 1.0000 - val_loss: 3.1457 - val_acc: 0.1917\n",
      "Epoch 19/100\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 1.3434 - acc: 0.6118 - val_loss: 3.9846 - val_acc: 0.1083\n",
      "Epoch 20/100\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 0.5824 - acc: 0.8118 - val_loss: 3.1073 - val_acc: 0.1833\n",
      "Epoch 21/100\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 0.0754 - acc: 0.9917 - val_loss: 3.0071 - val_acc: 0.1889\n",
      "Epoch 22/100\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 0.0319 - acc: 1.0000 - val_loss: 2.9765 - val_acc: 0.2111\n",
      "Epoch 23/100\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 0.0193 - acc: 1.0000 - val_loss: 2.9875 - val_acc: 0.2083\n",
      "Epoch 24/100\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 0.0126 - acc: 1.0000 - val_loss: 2.9859 - val_acc: 0.2194\n",
      "Epoch 25/100\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 0.0082 - acc: 1.0000 - val_loss: 3.0000 - val_acc: 0.2056\n",
      "Epoch 26/100\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 0.0056 - acc: 1.0000 - val_loss: 3.0205 - val_acc: 0.2333\n",
      "Epoch 27/100\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 0.0135 - acc: 0.9972 - val_loss: 3.5624 - val_acc: 0.1917\n",
      "Epoch 28/100\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 0.3339 - acc: 0.8861 - val_loss: 3.1684 - val_acc: 0.1722\n",
      "Epoch 29/100\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 0.0272 - acc: 0.9993 - val_loss: 3.1969 - val_acc: 0.1806\n",
      "Epoch 30/100\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 0.0108 - acc: 1.0000 - val_loss: 3.2133 - val_acc: 0.1694\n",
      "Epoch 31/100\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 0.0072 - acc: 1.0000 - val_loss: 3.2139 - val_acc: 0.1889\n",
      "Epoch 32/100\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 0.0052 - acc: 1.0000 - val_loss: 3.2483 - val_acc: 0.1917\n",
      "Epoch 33/100\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 3.3084 - val_acc: 0.2000\n",
      "Epoch 34/100\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 3.3512 - val_acc: 0.1917\n",
      "Epoch 35/100\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 3.4143 - val_acc: 0.2083\n",
      "Epoch 36/100\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 8.0366e-04 - acc: 1.0000 - val_loss: 3.5294 - val_acc: 0.1861\n",
      "Epoch 37/100\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 0.0461 - acc: 0.9854 - val_loss: 3.6648 - val_acc: 0.1972\n",
      "Epoch 38/100\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 0.0157 - acc: 0.9986 - val_loss: 3.3485 - val_acc: 0.2306\n",
      "Epoch 39/100\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 3.4311 - val_acc: 0.2417\n",
      "Epoch 40/100\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 3.4551 - val_acc: 0.2083\n",
      "Epoch 41/100\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 3.5357 - val_acc: 0.2083\n",
      "Epoch 42/100\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 8.5881e-04 - acc: 1.0000 - val_loss: 3.5863 - val_acc: 0.2056\n",
      "Epoch 43/100\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 5.8764e-04 - acc: 1.0000 - val_loss: 3.6657 - val_acc: 0.2083\n",
      "Epoch 44/100\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 3.9830e-04 - acc: 1.0000 - val_loss: 3.6924 - val_acc: 0.2167\n",
      "Epoch 45/100\n",
      "1440/1440 [==============================] - 2s 2ms/step - loss: 2.7166e-04 - acc: 1.0000 - val_loss: 3.8076 - val_acc: 0.2222\n",
      "Epoch 46/100\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 1.7377e-04 - acc: 1.0000 - val_loss: 3.8326 - val_acc: 0.2139\n",
      "Epoch 47/100\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 0.5362 - acc: 0.8257 - val_loss: 3.9029 - val_acc: 0.2250\n",
      "Epoch 48/100\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 0.0195 - acc: 0.9986 - val_loss: 3.9049 - val_acc: 0.2111\n",
      "Epoch 49/100\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 0.0053 - acc: 1.0000 - val_loss: 3.9223 - val_acc: 0.2056\n",
      "Epoch 50/100\n",
      "1440/1440 [==============================] - 2s 2ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 3.9180 - val_acc: 0.2000\n",
      "Epoch 51/100\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 3.9182 - val_acc: 0.2111\n",
      "Epoch 52/100\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 3.8659 - val_acc: 0.2306\n",
      "Epoch 53/100\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 3.8835 - val_acc: 0.2083\n",
      "Epoch 54/100\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 6.9888e-04 - acc: 1.0000 - val_loss: 3.9582 - val_acc: 0.2000\n",
      "Epoch 55/100\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 4.4697e-04 - acc: 1.0000 - val_loss: 3.9763 - val_acc: 0.1972\n",
      "Epoch 56/100\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 3.8626e-04 - acc: 1.0000 - val_loss: 4.1138 - val_acc: 0.1889\n",
      "Epoch 57/100\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 1.9790e-04 - acc: 1.0000 - val_loss: 4.1129 - val_acc: 0.2000\n",
      "Epoch 58/100\n",
      "1440/1440 [==============================] - 4s 2ms/step - loss: 1.1771e-04 - acc: 1.0000 - val_loss: 4.1720 - val_acc: 0.2028\n",
      "Epoch 59/100\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 7.9811e-05 - acc: 1.0000 - val_loss: 4.2672 - val_acc: 0.2028\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1440/1440 [==============================] - 3s 2ms/step - loss: 0.0078 - acc: 0.9958 - val_loss: 4.9327 - val_acc: 0.1500\n",
      "Epoch 61/100\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 0.4477 - acc: 0.8507 - val_loss: 4.1989 - val_acc: 0.2139\n",
      "Epoch 62/100\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 0.0208 - acc: 0.9944 - val_loss: 4.2183 - val_acc: 0.2111\n",
      "Epoch 63/100\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 4.1959 - val_acc: 0.1944\n",
      "Epoch 64/100\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 4.1344 - val_acc: 0.2083\n",
      "Epoch 65/100\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 7.9136e-04 - acc: 1.0000 - val_loss: 4.1722 - val_acc: 0.2000\n",
      "Epoch 66/100\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 5.2353e-04 - acc: 1.0000 - val_loss: 4.1848 - val_acc: 0.2111\n",
      "Epoch 67/100\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 3.5353e-04 - acc: 1.0000 - val_loss: 4.1993 - val_acc: 0.2056\n",
      "Epoch 68/100\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 2.4033e-04 - acc: 1.0000 - val_loss: 4.2336 - val_acc: 0.1972\n",
      "Epoch 69/100\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 1.6221e-04 - acc: 1.0000 - val_loss: 4.2501 - val_acc: 0.2111\n",
      "Epoch 70/100\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 1.1087e-04 - acc: 1.0000 - val_loss: 4.2875 - val_acc: 0.2083\n",
      "Epoch 71/100\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 7.6148e-05 - acc: 1.0000 - val_loss: 4.3392 - val_acc: 0.2028\n",
      "Epoch 72/100\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 5.2343e-05 - acc: 1.0000 - val_loss: 4.4079 - val_acc: 0.2083\n",
      "Epoch 73/100\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 3.5034e-05 - acc: 1.0000 - val_loss: 4.4927 - val_acc: 0.1917\n",
      "Epoch 74/100\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 3.1884e-05 - acc: 1.0000 - val_loss: 4.5642 - val_acc: 0.2167\n",
      "Epoch 75/100\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 1.4517e-05 - acc: 1.0000 - val_loss: 4.6422 - val_acc: 0.2000\n",
      "Epoch 76/100\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 9.7009e-06 - acc: 1.0000 - val_loss: 4.7926 - val_acc: 0.2167\n",
      "Epoch 77/100\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 0.3152 - acc: 0.9056 - val_loss: 4.4914 - val_acc: 0.2389\n",
      "Epoch 78/100\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 0.0073 - acc: 0.9979 - val_loss: 4.6047 - val_acc: 0.2167\n",
      "Epoch 79/100\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 4.5827 - val_acc: 0.2139\n",
      "Epoch 80/100\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 5.9684e-04 - acc: 1.0000 - val_loss: 4.5974 - val_acc: 0.2139\n",
      "Epoch 81/100\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 4.0691e-04 - acc: 1.0000 - val_loss: 4.6187 - val_acc: 0.2139\n",
      "Epoch 82/100\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 2.7982e-04 - acc: 1.0000 - val_loss: 4.6546 - val_acc: 0.2056\n",
      "Epoch 83/100\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 1.8925e-04 - acc: 1.0000 - val_loss: 4.6903 - val_acc: 0.2000\n",
      "Epoch 84/100\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 1.2908e-04 - acc: 1.0000 - val_loss: 4.7635 - val_acc: 0.2000\n",
      "Epoch 85/100\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 8.3427e-05 - acc: 1.0000 - val_loss: 4.8192 - val_acc: 0.1917\n",
      "Epoch 86/100\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 5.4955e-05 - acc: 1.0000 - val_loss: 4.8545 - val_acc: 0.1889\n",
      "Epoch 87/100\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 3.6712e-05 - acc: 1.0000 - val_loss: 4.8446 - val_acc: 0.1944\n",
      "Epoch 88/100\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 2.4373e-05 - acc: 1.0000 - val_loss: 4.9169 - val_acc: 0.1778\n",
      "Epoch 89/100\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 1.6016e-05 - acc: 1.0000 - val_loss: 4.9014 - val_acc: 0.1861\n",
      "Epoch 90/100\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 1.0616e-05 - acc: 1.0000 - val_loss: 5.0070 - val_acc: 0.1750\n",
      "Epoch 91/100\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 6.8900e-06 - acc: 1.0000 - val_loss: 4.9957 - val_acc: 0.1972\n",
      "Epoch 92/100\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 4.4608e-06 - acc: 1.0000 - val_loss: 5.1213 - val_acc: 0.1861\n",
      "Epoch 93/100\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 3.0629e-06 - acc: 1.0000 - val_loss: 5.2230 - val_acc: 0.1917\n",
      "Epoch 94/100\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 0.4215 - acc: 0.8792 - val_loss: 5.1235 - val_acc: 0.1944\n",
      "Epoch 95/100\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 0.0887 - acc: 0.9743 - val_loss: 4.9370 - val_acc: 0.1917\n",
      "Epoch 96/100\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 0.0136 - acc: 0.9965 - val_loss: 4.7585 - val_acc: 0.2083\n",
      "Epoch 97/100\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 4.8613 - val_acc: 0.2028\n",
      "Epoch 98/100\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 9.2921e-04 - acc: 1.0000 - val_loss: 4.8166 - val_acc: 0.2028\n",
      "Epoch 99/100\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 3.9551e-04 - acc: 1.0000 - val_loss: 4.8588 - val_acc: 0.1972\n",
      "Epoch 100/100\n",
      "1440/1440 [==============================] - 3s 2ms/step - loss: 2.5015e-04 - acc: 1.0000 - val_loss: 4.8662 - val_acc: 0.1889\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs=100, batch_size=128, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_10 (Embedding)     (None, 200, 100)          100000    \n",
      "_________________________________________________________________\n",
      "simple_rnn_8 (SimpleRNN)     (None, 200, 100)          20100     \n",
      "_________________________________________________________________\n",
      "simple_rnn_9 (SimpleRNN)     (None, 200, 100)          20100     \n",
      "_________________________________________________________________\n",
      "simple_rnn_10 (SimpleRNN)    (None, 100)               20100     \n",
      "=================================================================\n",
      "Total params: 160,300\n",
      "Trainable params: 160,300\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, SimpleRNN\n",
    "\n",
    "n_words = 1000\n",
    "output_dim = 100\n",
    "max_sentence_length = 200 \n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim = n_words, output_dim = 100, input_length = max_sentence_length))\n",
    "model.add(SimpleRNN(100, return_sequences=True))\n",
    "model.add(SimpleRNN(100, return_sequences=True))\n",
    "model.add(SimpleRNN(100))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_10 (Embedding)     (None, 200, 100)          100000    \n",
      "_________________________________________________________________\n",
      "simple_rnn_8 (SimpleRNN)     (None, 200, 100)          20100     \n",
      "_________________________________________________________________\n",
      "simple_rnn_9 (SimpleRNN)     (None, 200, 100)          20100     \n",
      "_________________________________________________________________\n",
      "simple_rnn_10 (SimpleRNN)    (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 7)                 707       \n",
      "=================================================================\n",
      "Total params: 161,007\n",
      "Trainable params: 161,007\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.add(Dense(7, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1440 samples, validate on 360 samples\n",
      "Epoch 1/30\n",
      "1440/1440 [==============================] - 7s 5ms/step - loss: 3.2430e-05 - acc: 1.0000 - val_loss: 6.6745 - val_acc: 0.1556\n",
      "Epoch 2/30\n",
      "1440/1440 [==============================] - 7s 5ms/step - loss: 2.0631e-05 - acc: 1.0000 - val_loss: 6.8496 - val_acc: 0.1556\n",
      "Epoch 3/30\n",
      "1440/1440 [==============================] - 7s 5ms/step - loss: 1.2625e-05 - acc: 1.0000 - val_loss: 7.0048 - val_acc: 0.1556\n",
      "Epoch 4/30\n",
      "1440/1440 [==============================] - 7s 5ms/step - loss: 7.6063e-06 - acc: 1.0000 - val_loss: 7.1973 - val_acc: 0.1583\n",
      "Epoch 5/30\n",
      "1440/1440 [==============================] - 7s 5ms/step - loss: 5.3649e-06 - acc: 1.0000 - val_loss: 7.4218 - val_acc: 0.1556\n",
      "Epoch 6/30\n",
      "1440/1440 [==============================] - 7s 5ms/step - loss: 2.8226e-06 - acc: 1.0000 - val_loss: 7.5816 - val_acc: 0.1556\n",
      "Epoch 7/30\n",
      "1440/1440 [==============================] - 8s 5ms/step - loss: 1.6924e-06 - acc: 1.0000 - val_loss: 7.7757 - val_acc: 0.1556\n",
      "Epoch 8/30\n",
      "1440/1440 [==============================] - 7s 5ms/step - loss: 9.8849e-07 - acc: 1.0000 - val_loss: 7.9079 - val_acc: 0.1472\n",
      "Epoch 9/30\n",
      "1440/1440 [==============================] - 7s 5ms/step - loss: 6.2829e-07 - acc: 1.0000 - val_loss: 7.9932 - val_acc: 0.1556\n",
      "Epoch 10/30\n",
      "1440/1440 [==============================] - 7s 5ms/step - loss: 4.1703e-07 - acc: 1.0000 - val_loss: 8.1294 - val_acc: 0.1444\n",
      "Epoch 11/30\n",
      "1440/1440 [==============================] - 8s 5ms/step - loss: 2.9181e-07 - acc: 1.0000 - val_loss: 8.2241 - val_acc: 0.1472\n",
      "Epoch 12/30\n",
      "1440/1440 [==============================] - 7s 5ms/step - loss: 2.0733e-07 - acc: 1.0000 - val_loss: 8.2701 - val_acc: 0.1583\n",
      "Epoch 13/30\n",
      "1440/1440 [==============================] - 7s 5ms/step - loss: 1.6602e-07 - acc: 1.0000 - val_loss: 8.3661 - val_acc: 0.1556\n",
      "Epoch 14/30\n",
      "1440/1440 [==============================] - 7s 5ms/step - loss: 1.4272e-07 - acc: 1.0000 - val_loss: 8.4046 - val_acc: 0.1528\n",
      "Epoch 15/30\n",
      "1440/1440 [==============================] - 7s 5ms/step - loss: 1.3146e-07 - acc: 1.0000 - val_loss: 8.3917 - val_acc: 0.1528\n",
      "Epoch 16/30\n",
      "1440/1440 [==============================] - 7s 5ms/step - loss: 1.2542e-07 - acc: 1.0000 - val_loss: 8.3986 - val_acc: 0.1583\n",
      "Epoch 17/30\n",
      "1440/1440 [==============================] - 8s 5ms/step - loss: 1.2285e-07 - acc: 1.0000 - val_loss: 8.4289 - val_acc: 0.1528\n",
      "Epoch 18/30\n",
      "1440/1440 [==============================] - 7s 5ms/step - loss: 1.2157e-07 - acc: 1.0000 - val_loss: 8.4713 - val_acc: 0.1528\n",
      "Epoch 19/30\n",
      "1440/1440 [==============================] - 8s 6ms/step - loss: 1.2029e-07 - acc: 1.0000 - val_loss: 8.4758 - val_acc: 0.1556\n",
      "Epoch 20/30\n",
      "1440/1440 [==============================] - 8s 5ms/step - loss: 1.2016e-07 - acc: 1.0000 - val_loss: 8.4835 - val_acc: 0.1583\n",
      "Epoch 21/30\n",
      "1440/1440 [==============================] - 10s 7ms/step - loss: 1.2020e-07 - acc: 1.0000 - val_loss: 8.4778 - val_acc: 0.1583\n",
      "Epoch 22/30\n",
      "1440/1440 [==============================] - 7s 5ms/step - loss: 1.1991e-07 - acc: 1.0000 - val_loss: 8.4738 - val_acc: 0.1556\n",
      "Epoch 23/30\n",
      "1440/1440 [==============================] - 8s 5ms/step - loss: 1.1983e-07 - acc: 1.0000 - val_loss: 8.4788 - val_acc: 0.1556\n",
      "Epoch 24/30\n",
      "1440/1440 [==============================] - 7s 5ms/step - loss: 1.1966e-07 - acc: 1.0000 - val_loss: 8.4982 - val_acc: 0.1472\n",
      "Epoch 25/30\n",
      "1440/1440 [==============================] - 8s 5ms/step - loss: 1.1962e-07 - acc: 1.0000 - val_loss: 8.4927 - val_acc: 0.1500\n",
      "Epoch 26/30\n",
      "1440/1440 [==============================] - 8s 5ms/step - loss: 1.1962e-07 - acc: 1.0000 - val_loss: 8.5116 - val_acc: 0.1528\n",
      "Epoch 27/30\n",
      "1440/1440 [==============================] - 7s 5ms/step - loss: 1.1983e-07 - acc: 1.0000 - val_loss: 8.5082 - val_acc: 0.1528\n",
      "Epoch 28/30\n",
      "1440/1440 [==============================] - 7s 5ms/step - loss: 1.1950e-07 - acc: 1.0000 - val_loss: 8.5094 - val_acc: 0.1528\n",
      "Epoch 29/30\n",
      "1440/1440 [==============================] - 7s 5ms/step - loss: 1.1954e-07 - acc: 1.0000 - val_loss: 8.5117 - val_acc: 0.1528\n",
      "Epoch 30/30\n",
      "1440/1440 [==============================] - 7s 5ms/step - loss: 1.1942e-07 - acc: 1.0000 - val_loss: 8.5054 - val_acc: 0.1528\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs=30, batch_size=128, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "very poor result! A random classifier would perform similarly!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1440 samples, validate on 360 samples\n",
      "Epoch 1/80\n",
      "1440/1440 [==============================] - 9s 6ms/step - loss: 1.9429 - acc: 0.1868 - val_loss: 1.9117 - val_acc: 0.2528\n",
      "Epoch 2/80\n",
      "1440/1440 [==============================] - 9s 6ms/step - loss: 1.8942 - acc: 0.2104 - val_loss: 1.8804 - val_acc: 0.2611\n",
      "Epoch 3/80\n",
      "1440/1440 [==============================] - 8s 6ms/step - loss: 1.8684 - acc: 0.2924 - val_loss: 1.8548 - val_acc: 0.2694\n",
      "Epoch 4/80\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 1.8255 - acc: 0.3194 - val_loss: 1.7098 - val_acc: 0.3000\n",
      "Epoch 5/80\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 1.6553 - acc: 0.3417 - val_loss: 1.7953 - val_acc: 0.2806\n",
      "Epoch 6/80\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 1.5982 - acc: 0.3514 - val_loss: 1.5798 - val_acc: 0.3472\n",
      "Epoch 7/80\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 1.5768 - acc: 0.3882 - val_loss: 1.5183 - val_acc: 0.3750\n",
      "Epoch 8/80\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 1.4535 - acc: 0.4215 - val_loss: 1.4134 - val_acc: 0.4444\n",
      "Epoch 9/80\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 1.4547 - acc: 0.4514 - val_loss: 1.3903 - val_acc: 0.4528\n",
      "Epoch 10/80\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 1.3403 - acc: 0.4868 - val_loss: 1.6033 - val_acc: 0.3972\n",
      "Epoch 11/80\n",
      "1440/1440 [==============================] - 7s 5ms/step - loss: 1.2923 - acc: 0.5007 - val_loss: 1.4744 - val_acc: 0.3806\n",
      "Epoch 12/80\n",
      "1440/1440 [==============================] - 9s 6ms/step - loss: 1.2752 - acc: 0.5021 - val_loss: 1.7328 - val_acc: 0.3417\n",
      "Epoch 13/80\n",
      "1440/1440 [==============================] - 8s 6ms/step - loss: 1.2485 - acc: 0.5139 - val_loss: 1.3432 - val_acc: 0.4833\n",
      "Epoch 14/80\n",
      "1440/1440 [==============================] - 7s 5ms/step - loss: 1.1502 - acc: 0.5771 - val_loss: 1.3398 - val_acc: 0.4222\n",
      "Epoch 15/80\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 1.1997 - acc: 0.5465 - val_loss: 1.2976 - val_acc: 0.4361\n",
      "Epoch 16/80\n",
      "1440/1440 [==============================] - 7s 5ms/step - loss: 1.0614 - acc: 0.6007 - val_loss: 1.3868 - val_acc: 0.4083\n",
      "Epoch 17/80\n",
      "1440/1440 [==============================] - 7s 5ms/step - loss: 1.0406 - acc: 0.6340 - val_loss: 1.3331 - val_acc: 0.3972\n",
      "Epoch 18/80\n",
      "1440/1440 [==============================] - 7s 5ms/step - loss: 0.9677 - acc: 0.6486 - val_loss: 1.8992 - val_acc: 0.3444\n",
      "Epoch 19/80\n",
      "1440/1440 [==============================] - 7s 5ms/step - loss: 0.9690 - acc: 0.6750 - val_loss: 1.2391 - val_acc: 0.4861\n",
      "Epoch 20/80\n",
      "1440/1440 [==============================] - 8s 5ms/step - loss: 0.9389 - acc: 0.6694 - val_loss: 1.4904 - val_acc: 0.4861\n",
      "Epoch 21/80\n",
      "1440/1440 [==============================] - 8s 5ms/step - loss: 0.8944 - acc: 0.6965 - val_loss: 1.3818 - val_acc: 0.4722\n",
      "Epoch 22/80\n",
      "1440/1440 [==============================] - 8s 6ms/step - loss: 0.8681 - acc: 0.7104 - val_loss: 1.6443 - val_acc: 0.3778\n",
      "Epoch 23/80\n",
      "1440/1440 [==============================] - 7s 5ms/step - loss: 0.8424 - acc: 0.7181 - val_loss: 1.3416 - val_acc: 0.5306\n",
      "Epoch 24/80\n",
      "1440/1440 [==============================] - 7s 5ms/step - loss: 0.7379 - acc: 0.7528 - val_loss: 1.2438 - val_acc: 0.5222\n",
      "Epoch 25/80\n",
      "1440/1440 [==============================] - 8s 6ms/step - loss: 0.9828 - acc: 0.6979 - val_loss: 1.2410 - val_acc: 0.5583\n",
      "Epoch 26/80\n",
      "1440/1440 [==============================] - 8s 5ms/step - loss: 0.7274 - acc: 0.7632 - val_loss: 1.2105 - val_acc: 0.5556\n",
      "Epoch 27/80\n",
      "1440/1440 [==============================] - 7s 5ms/step - loss: 0.6349 - acc: 0.7917 - val_loss: 1.2272 - val_acc: 0.5639\n",
      "Epoch 28/80\n",
      "1440/1440 [==============================] - 8s 5ms/step - loss: 0.5296 - acc: 0.8382 - val_loss: 1.1594 - val_acc: 0.5639\n",
      "Epoch 29/80\n",
      "1440/1440 [==============================] - 7s 5ms/step - loss: 0.7006 - acc: 0.7542 - val_loss: 1.8055 - val_acc: 0.4889\n",
      "Epoch 30/80\n",
      "1440/1440 [==============================] - 9s 6ms/step - loss: 0.5844 - acc: 0.8229 - val_loss: 1.2089 - val_acc: 0.6278\n",
      "Epoch 31/80\n",
      "1440/1440 [==============================] - 9s 6ms/step - loss: 0.5280 - acc: 0.8410 - val_loss: 1.2818 - val_acc: 0.5556\n",
      "Epoch 32/80\n",
      "1440/1440 [==============================] - 8s 6ms/step - loss: 0.5766 - acc: 0.8132 - val_loss: 1.1203 - val_acc: 0.6278\n",
      "Epoch 33/80\n",
      "1440/1440 [==============================] - 7s 5ms/step - loss: 0.5262 - acc: 0.8215 - val_loss: 1.2412 - val_acc: 0.5472\n",
      "Epoch 34/80\n",
      "1440/1440 [==============================] - 7s 5ms/step - loss: 0.4152 - acc: 0.8764 - val_loss: 1.3815 - val_acc: 0.5444\n",
      "Epoch 35/80\n",
      "1440/1440 [==============================] - 11s 8ms/step - loss: 0.5378 - acc: 0.8396 - val_loss: 1.2407 - val_acc: 0.6056\n",
      "Epoch 36/80\n",
      "1440/1440 [==============================] - 10s 7ms/step - loss: 0.4025 - acc: 0.8771 - val_loss: 1.4845 - val_acc: 0.4944\n",
      "Epoch 37/80\n",
      "1440/1440 [==============================] - 9s 6ms/step - loss: 0.3989 - acc: 0.8799 - val_loss: 1.5527 - val_acc: 0.5833\n",
      "Epoch 38/80\n",
      "1440/1440 [==============================] - 7s 5ms/step - loss: 0.4369 - acc: 0.8660 - val_loss: 1.1912 - val_acc: 0.6194\n",
      "Epoch 39/80\n",
      "1440/1440 [==============================] - 7s 5ms/step - loss: 0.3224 - acc: 0.9007 - val_loss: 1.3955 - val_acc: 0.5806\n",
      "Epoch 40/80\n",
      "1440/1440 [==============================] - 8s 5ms/step - loss: 0.4104 - acc: 0.8708 - val_loss: 1.6402 - val_acc: 0.5861\n",
      "Epoch 41/80\n",
      "1440/1440 [==============================] - 7s 5ms/step - loss: 0.3695 - acc: 0.8958 - val_loss: 1.2347 - val_acc: 0.6000\n",
      "Epoch 42/80\n",
      "1440/1440 [==============================] - 10s 7ms/step - loss: 0.3257 - acc: 0.8944 - val_loss: 1.2549 - val_acc: 0.6222\n",
      "Epoch 43/80\n",
      "1440/1440 [==============================] - 10s 7ms/step - loss: 0.2306 - acc: 0.9354 - val_loss: 1.2440 - val_acc: 0.6278\n",
      "Epoch 44/80\n",
      "1440/1440 [==============================] - 7s 5ms/step - loss: 0.3614 - acc: 0.8924 - val_loss: 1.2243 - val_acc: 0.6250\n",
      "Epoch 45/80\n",
      "1440/1440 [==============================] - 7s 5ms/step - loss: 0.3476 - acc: 0.9104 - val_loss: 1.3464 - val_acc: 0.5750\n",
      "Epoch 46/80\n",
      "1440/1440 [==============================] - 7s 5ms/step - loss: 0.2729 - acc: 0.9229 - val_loss: 1.2750 - val_acc: 0.6389\n",
      "Epoch 47/80\n",
      "1440/1440 [==============================] - 7s 5ms/step - loss: 0.1872 - acc: 0.9465 - val_loss: 1.2857 - val_acc: 0.6222\n",
      "Epoch 48/80\n",
      "1440/1440 [==============================] - 7s 5ms/step - loss: 0.1856 - acc: 0.9500 - val_loss: 1.3835 - val_acc: 0.6083\n",
      "Epoch 49/80\n",
      "1440/1440 [==============================] - 7s 5ms/step - loss: 0.2623 - acc: 0.9264 - val_loss: 1.3204 - val_acc: 0.6056\n",
      "Epoch 50/80\n",
      "1440/1440 [==============================] - 7s 5ms/step - loss: 0.1874 - acc: 0.9424 - val_loss: 1.3625 - val_acc: 0.5861\n",
      "Epoch 51/80\n",
      "1440/1440 [==============================] - 7s 5ms/step - loss: 0.2530 - acc: 0.9292 - val_loss: 1.4907 - val_acc: 0.5806\n",
      "Epoch 52/80\n",
      "1440/1440 [==============================] - 7s 5ms/step - loss: 0.1079 - acc: 0.9688 - val_loss: 1.3467 - val_acc: 0.6389\n",
      "Epoch 53/80\n",
      "1440/1440 [==============================] - 8s 5ms/step - loss: 0.2581 - acc: 0.9292 - val_loss: 1.3824 - val_acc: 0.6139\n",
      "Epoch 54/80\n",
      "1440/1440 [==============================] - 7s 5ms/step - loss: 0.0944 - acc: 0.9785 - val_loss: 1.4425 - val_acc: 0.6306\n",
      "Epoch 55/80\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.2341 - acc: 0.9396 - val_loss: 1.4300 - val_acc: 0.6111\n",
      "Epoch 56/80\n",
      "1440/1440 [==============================] - 7s 5ms/step - loss: 0.0846 - acc: 0.9806 - val_loss: 1.4869 - val_acc: 0.6278\n",
      "Epoch 57/80\n",
      "1440/1440 [==============================] - 7s 5ms/step - loss: 0.2070 - acc: 0.9465 - val_loss: 1.5008 - val_acc: 0.6111\n",
      "Epoch 58/80\n",
      "1440/1440 [==============================] - 7s 5ms/step - loss: 0.0667 - acc: 0.9840 - val_loss: 1.6216 - val_acc: 0.5833\n",
      "Epoch 59/80\n",
      "1440/1440 [==============================] - 9s 6ms/step - loss: 0.1368 - acc: 0.9653 - val_loss: 1.5082 - val_acc: 0.6250\n",
      "Epoch 60/80\n",
      "1440/1440 [==============================] - 8s 5ms/step - loss: 0.1275 - acc: 0.9701 - val_loss: 1.6134 - val_acc: 0.5694\n",
      "Epoch 61/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1440/1440 [==============================] - 9s 6ms/step - loss: 0.2227 - acc: 0.9618 - val_loss: 1.5737 - val_acc: 0.6472\n",
      "Epoch 62/80\n",
      "1440/1440 [==============================] - 9s 6ms/step - loss: 0.0567 - acc: 0.9861 - val_loss: 1.6857 - val_acc: 0.6000\n",
      "Epoch 63/80\n",
      "1440/1440 [==============================] - 8s 6ms/step - loss: 0.0762 - acc: 0.9806 - val_loss: 1.8288 - val_acc: 0.5833\n",
      "Epoch 64/80\n",
      "1440/1440 [==============================] - 7s 5ms/step - loss: 0.4341 - acc: 0.9188 - val_loss: 1.8154 - val_acc: 0.5389\n",
      "Epoch 65/80\n",
      "1440/1440 [==============================] - 7s 5ms/step - loss: 0.0708 - acc: 0.9840 - val_loss: 1.6436 - val_acc: 0.5778\n",
      "Epoch 66/80\n",
      "1440/1440 [==============================] - 7s 5ms/step - loss: 0.0309 - acc: 0.9986 - val_loss: 1.6363 - val_acc: 0.5944\n",
      "Epoch 67/80\n",
      "1440/1440 [==============================] - 7s 5ms/step - loss: 0.0226 - acc: 0.9993 - val_loss: 1.6593 - val_acc: 0.6111\n",
      "Epoch 68/80\n",
      "1440/1440 [==============================] - 8s 5ms/step - loss: 0.0181 - acc: 1.0000 - val_loss: 1.6634 - val_acc: 0.6111\n",
      "Epoch 69/80\n",
      "1440/1440 [==============================] - 9s 6ms/step - loss: 0.0460 - acc: 0.9889 - val_loss: 1.6671 - val_acc: 0.6056\n",
      "Epoch 70/80\n",
      "1440/1440 [==============================] - 7s 5ms/step - loss: 0.0152 - acc: 0.9993 - val_loss: 1.7966 - val_acc: 0.6000\n",
      "Epoch 71/80\n",
      "1440/1440 [==============================] - 7s 5ms/step - loss: 0.1435 - acc: 0.9597 - val_loss: 1.6952 - val_acc: 0.6056\n",
      "Epoch 72/80\n",
      "1440/1440 [==============================] - 7s 5ms/step - loss: 0.0218 - acc: 0.9965 - val_loss: 1.8127 - val_acc: 0.6028\n",
      "Epoch 73/80\n",
      "1440/1440 [==============================] - 8s 5ms/step - loss: 0.0520 - acc: 0.9875 - val_loss: 1.8089 - val_acc: 0.5861\n",
      "Epoch 74/80\n",
      "1440/1440 [==============================] - 8s 6ms/step - loss: 0.0345 - acc: 0.9924 - val_loss: 1.7166 - val_acc: 0.5917\n",
      "Epoch 75/80\n",
      "1440/1440 [==============================] - 8s 6ms/step - loss: 0.1144 - acc: 0.9722 - val_loss: 1.9144 - val_acc: 0.5639\n",
      "Epoch 76/80\n",
      "1440/1440 [==============================] - 8s 6ms/step - loss: 0.0460 - acc: 0.9910 - val_loss: 1.8762 - val_acc: 0.5750\n",
      "Epoch 77/80\n",
      "1440/1440 [==============================] - 12s 8ms/step - loss: 0.0188 - acc: 0.9965 - val_loss: 1.8592 - val_acc: 0.5806\n",
      "Epoch 78/80\n",
      "1440/1440 [==============================] - 9s 6ms/step - loss: 0.0690 - acc: 0.9833 - val_loss: 1.8390 - val_acc: 0.5806\n",
      "Epoch 79/80\n",
      "1440/1440 [==============================] - 8s 5ms/step - loss: 0.0289 - acc: 0.9958 - val_loss: 1.9954 - val_acc: 0.6000\n",
      "Epoch 80/80\n",
      "1440/1440 [==============================] - 7s 5ms/step - loss: 0.0372 - acc: 0.9910 - val_loss: 1.9042 - val_acc: 0.5889\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim = n_words, output_dim = 100, input_length = max_sentence_length))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "history = model.fit(x_train, y_train, epochs=80, batch_size=128, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(x_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.17295569896698"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.535"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1440 samples, validate on 360 samples\n",
      "Epoch 1/40\n",
      "1440/1440 [==============================] - 27s 19ms/step - loss: 1.9287 - acc: 0.1889 - val_loss: 1.9076 - val_acc: 0.2444\n",
      "Epoch 2/40\n",
      "1440/1440 [==============================] - 21s 15ms/step - loss: 1.8037 - acc: 0.3021 - val_loss: 1.7238 - val_acc: 0.3083\n",
      "Epoch 3/40\n",
      "1440/1440 [==============================] - 23s 16ms/step - loss: 1.6053 - acc: 0.3687 - val_loss: 1.5926 - val_acc: 0.3833\n",
      "Epoch 4/40\n",
      "1440/1440 [==============================] - 23s 16ms/step - loss: 1.4751 - acc: 0.3972 - val_loss: 1.5985 - val_acc: 0.3722\n",
      "Epoch 5/40\n",
      "1440/1440 [==============================] - 22s 15ms/step - loss: 1.3497 - acc: 0.4347 - val_loss: 1.5836 - val_acc: 0.3944\n",
      "Epoch 6/40\n",
      "1440/1440 [==============================] - 22s 15ms/step - loss: 1.2750 - acc: 0.4840 - val_loss: 1.6237 - val_acc: 0.4056\n",
      "Epoch 7/40\n",
      "1440/1440 [==============================] - 22s 15ms/step - loss: 1.2175 - acc: 0.5104 - val_loss: 1.5345 - val_acc: 0.4500\n",
      "Epoch 8/40\n",
      "1440/1440 [==============================] - 21s 15ms/step - loss: 1.2170 - acc: 0.5354 - val_loss: 1.4839 - val_acc: 0.4944\n",
      "Epoch 9/40\n",
      "1440/1440 [==============================] - 21s 15ms/step - loss: 1.0569 - acc: 0.5903 - val_loss: 1.8428 - val_acc: 0.2778\n",
      "Epoch 10/40\n",
      "1440/1440 [==============================] - 22s 15ms/step - loss: 1.0984 - acc: 0.5542 - val_loss: 1.6358 - val_acc: 0.4500\n",
      "Epoch 11/40\n",
      "1440/1440 [==============================] - 22s 16ms/step - loss: 0.9815 - acc: 0.6167 - val_loss: 1.7757 - val_acc: 0.3972\n",
      "Epoch 12/40\n",
      "1440/1440 [==============================] - 21s 15ms/step - loss: 1.0492 - acc: 0.5757 - val_loss: 1.5776 - val_acc: 0.4361\n",
      "Epoch 13/40\n",
      "1440/1440 [==============================] - 21s 14ms/step - loss: 0.8563 - acc: 0.6757 - val_loss: 1.5652 - val_acc: 0.4972\n",
      "Epoch 14/40\n",
      "1440/1440 [==============================] - 21s 15ms/step - loss: 0.8701 - acc: 0.6556 - val_loss: 1.7282 - val_acc: 0.4167\n",
      "Epoch 15/40\n",
      "1440/1440 [==============================] - 20s 14ms/step - loss: 0.8077 - acc: 0.6979 - val_loss: 1.7005 - val_acc: 0.4861\n",
      "Epoch 16/40\n",
      "1440/1440 [==============================] - 21s 15ms/step - loss: 0.8487 - acc: 0.6764 - val_loss: 1.6516 - val_acc: 0.4500\n",
      "Epoch 17/40\n",
      "1440/1440 [==============================] - 22s 15ms/step - loss: 0.7994 - acc: 0.6958 - val_loss: 1.7341 - val_acc: 0.4389\n",
      "Epoch 18/40\n",
      "1440/1440 [==============================] - 26s 18ms/step - loss: 0.7559 - acc: 0.7160 - val_loss: 2.8049 - val_acc: 0.4139\n",
      "Epoch 19/40\n",
      "1440/1440 [==============================] - 25s 17ms/step - loss: 0.8522 - acc: 0.7194 - val_loss: 1.6468 - val_acc: 0.4889\n",
      "Epoch 20/40\n",
      "1440/1440 [==============================] - 22s 15ms/step - loss: 0.7010 - acc: 0.7354 - val_loss: 1.7889 - val_acc: 0.4778\n",
      "Epoch 21/40\n",
      "1440/1440 [==============================] - 21s 15ms/step - loss: 0.6540 - acc: 0.7528 - val_loss: 1.7412 - val_acc: 0.4639\n",
      "Epoch 22/40\n",
      "1440/1440 [==============================] - 22s 15ms/step - loss: 0.6672 - acc: 0.7562 - val_loss: 1.7637 - val_acc: 0.4972\n",
      "Epoch 23/40\n",
      "1440/1440 [==============================] - 19s 14ms/step - loss: 0.6412 - acc: 0.7694 - val_loss: 1.8373 - val_acc: 0.4444\n",
      "Epoch 24/40\n",
      "1440/1440 [==============================] - 21s 15ms/step - loss: 0.6091 - acc: 0.7736 - val_loss: 1.7546 - val_acc: 0.5361\n",
      "Epoch 25/40\n",
      "1440/1440 [==============================] - 21s 15ms/step - loss: 0.6368 - acc: 0.7667 - val_loss: 1.7635 - val_acc: 0.5250\n",
      "Epoch 26/40\n",
      "1440/1440 [==============================] - 21s 14ms/step - loss: 0.5272 - acc: 0.8014 - val_loss: 1.8759 - val_acc: 0.4667\n",
      "Epoch 27/40\n",
      "1440/1440 [==============================] - 19s 13ms/step - loss: 0.5984 - acc: 0.7944 - val_loss: 1.7891 - val_acc: 0.5000\n",
      "Epoch 28/40\n",
      "1440/1440 [==============================] - 19s 13ms/step - loss: 0.5417 - acc: 0.8160 - val_loss: 1.8326 - val_acc: 0.5333\n",
      "Epoch 29/40\n",
      "1440/1440 [==============================] - 19s 13ms/step - loss: 0.4831 - acc: 0.8306 - val_loss: 2.0975 - val_acc: 0.4000\n",
      "Epoch 30/40\n",
      "1440/1440 [==============================] - 19s 13ms/step - loss: 0.4932 - acc: 0.8181 - val_loss: 2.1492 - val_acc: 0.4722\n",
      "Epoch 31/40\n",
      "1440/1440 [==============================] - 19s 13ms/step - loss: 0.4962 - acc: 0.8326 - val_loss: 1.7903 - val_acc: 0.5139\n",
      "Epoch 32/40\n",
      "1440/1440 [==============================] - 19s 13ms/step - loss: 0.3542 - acc: 0.8875 - val_loss: 1.8445 - val_acc: 0.5583\n",
      "Epoch 33/40\n",
      "1440/1440 [==============================] - 19s 13ms/step - loss: 0.3996 - acc: 0.8688 - val_loss: 1.9830 - val_acc: 0.5139\n",
      "Epoch 34/40\n",
      "1440/1440 [==============================] - 19s 13ms/step - loss: 0.4379 - acc: 0.8507 - val_loss: 1.7628 - val_acc: 0.5694\n",
      "Epoch 35/40\n",
      "1440/1440 [==============================] - 19s 13ms/step - loss: 0.3550 - acc: 0.8799 - val_loss: 1.8739 - val_acc: 0.5472\n",
      "Epoch 36/40\n",
      "1440/1440 [==============================] - 19s 13ms/step - loss: 0.4046 - acc: 0.8681 - val_loss: 1.9904 - val_acc: 0.5000\n",
      "Epoch 37/40\n",
      "1440/1440 [==============================] - 19s 13ms/step - loss: 0.3965 - acc: 0.8701 - val_loss: 1.9571 - val_acc: 0.5250\n",
      "Epoch 38/40\n",
      "1440/1440 [==============================] - 19s 13ms/step - loss: 0.3197 - acc: 0.8931 - val_loss: 2.0799 - val_acc: 0.4861\n",
      "Epoch 39/40\n",
      "1440/1440 [==============================] - 19s 13ms/step - loss: 0.2884 - acc: 0.9153 - val_loss: 2.0566 - val_acc: 0.5167\n",
      "Epoch 40/40\n",
      "1440/1440 [==============================] - 19s 13ms/step - loss: 0.2696 - acc: 0.9160 - val_loss: 2.1721 - val_acc: 0.4833\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim = n_words, output_dim = 100, input_length = max_sentence_length))\n",
    "model.add(LSTM(100, return_sequences=True))\n",
    "model.add(LSTM(100, return_sequences=True))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "history = model.fit(x_train, y_train, epochs=40, batch_size=128, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(x_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.1009898948669434"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1440 samples, validate on 360 samples\n",
      "Epoch 1/50\n",
      "1440/1440 [==============================] - 8s 6ms/step - loss: 1.9319 - acc: 0.1882 - val_loss: 1.9091 - val_acc: 0.2306\n",
      "Epoch 2/50\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 1.8868 - acc: 0.2069 - val_loss: 1.8800 - val_acc: 0.2389\n",
      "Epoch 3/50\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 2.0737 - acc: 0.2868 - val_loss: 2.9031 - val_acc: 0.2722\n",
      "Epoch 4/50\n",
      "1440/1440 [==============================] - 7s 5ms/step - loss: 1.8483 - acc: 0.3972 - val_loss: 1.7770 - val_acc: 0.3167\n",
      "Epoch 5/50\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 1.6678 - acc: 0.4167 - val_loss: 1.6581 - val_acc: 0.3250\n",
      "Epoch 6/50\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 1.6608 - acc: 0.4236 - val_loss: 1.7790 - val_acc: 0.2972\n",
      "Epoch 7/50\n",
      "1440/1440 [==============================] - 7s 5ms/step - loss: 1.5249 - acc: 0.4653 - val_loss: 2.8480 - val_acc: 0.2833\n",
      "Epoch 8/50\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 1.6525 - acc: 0.4653 - val_loss: 1.7451 - val_acc: 0.3194\n",
      "Epoch 9/50\n",
      "1440/1440 [==============================] - 7s 5ms/step - loss: 1.4338 - acc: 0.5208 - val_loss: 1.6151 - val_acc: 0.3500\n",
      "Epoch 10/50\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 1.3834 - acc: 0.5139 - val_loss: 1.7191 - val_acc: 0.3000\n",
      "Epoch 11/50\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 1.3144 - acc: 0.5729 - val_loss: 1.6919 - val_acc: 0.3194\n",
      "Epoch 12/50\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 1.2638 - acc: 0.5674 - val_loss: 1.6149 - val_acc: 0.3722\n",
      "Epoch 13/50\n",
      "1440/1440 [==============================] - 7s 5ms/step - loss: 1.2312 - acc: 0.6014 - val_loss: 1.7742 - val_acc: 0.3667\n",
      "Epoch 14/50\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 1.1539 - acc: 0.6333 - val_loss: 1.6460 - val_acc: 0.3500\n",
      "Epoch 15/50\n",
      "1440/1440 [==============================] - 6s 5ms/step - loss: 1.0568 - acc: 0.6493 - val_loss: 1.6494 - val_acc: 0.3278\n",
      "Epoch 16/50\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.9333 - acc: 0.6965 - val_loss: 1.7717 - val_acc: 0.3444\n",
      "Epoch 17/50\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.8881 - acc: 0.7028 - val_loss: 1.7124 - val_acc: 0.3750\n",
      "Epoch 18/50\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.8133 - acc: 0.7208 - val_loss: 1.5557 - val_acc: 0.4250\n",
      "Epoch 19/50\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.7061 - acc: 0.7819 - val_loss: 1.7811 - val_acc: 0.4361\n",
      "Epoch 20/50\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.6831 - acc: 0.7799 - val_loss: 1.6342 - val_acc: 0.4028\n",
      "Epoch 21/50\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.5927 - acc: 0.8236 - val_loss: 1.7284 - val_acc: 0.4056\n",
      "Epoch 22/50\n",
      "1440/1440 [==============================] - 5s 4ms/step - loss: 0.5602 - acc: 0.8306 - val_loss: 1.6396 - val_acc: 0.4611\n",
      "Epoch 23/50\n",
      "1440/1440 [==============================] - 7s 5ms/step - loss: 0.4892 - acc: 0.8465 - val_loss: 1.8083 - val_acc: 0.4361\n",
      "Epoch 24/50\n",
      "1440/1440 [==============================] - 8s 5ms/step - loss: 0.4963 - acc: 0.8424 - val_loss: 1.8579 - val_acc: 0.4389\n",
      "Epoch 25/50\n",
      "1440/1440 [==============================] - 7s 5ms/step - loss: 0.4454 - acc: 0.8618 - val_loss: 1.8054 - val_acc: 0.4361\n",
      "Epoch 26/50\n",
      "1440/1440 [==============================] - 6s 5ms/step - loss: 0.4067 - acc: 0.8701 - val_loss: 1.8356 - val_acc: 0.4417\n",
      "Epoch 27/50\n",
      "1440/1440 [==============================] - 7s 5ms/step - loss: 0.3288 - acc: 0.9076 - val_loss: 1.8718 - val_acc: 0.4417\n",
      "Epoch 28/50\n",
      "1440/1440 [==============================] - 7s 5ms/step - loss: 0.3508 - acc: 0.8868 - val_loss: 1.9651 - val_acc: 0.4694\n",
      "Epoch 29/50\n",
      "1440/1440 [==============================] - 7s 5ms/step - loss: 0.3239 - acc: 0.9000 - val_loss: 1.9729 - val_acc: 0.4278\n",
      "Epoch 30/50\n",
      "1440/1440 [==============================] - 8s 6ms/step - loss: 0.2800 - acc: 0.9153 - val_loss: 2.0025 - val_acc: 0.4889\n",
      "Epoch 31/50\n",
      "1440/1440 [==============================] - 7s 5ms/step - loss: 0.3192 - acc: 0.9056 - val_loss: 2.1370 - val_acc: 0.4528\n",
      "Epoch 32/50\n",
      "1440/1440 [==============================] - 7s 5ms/step - loss: 0.2361 - acc: 0.9306 - val_loss: 2.1472 - val_acc: 0.4639\n",
      "Epoch 33/50\n",
      "1440/1440 [==============================] - 7s 5ms/step - loss: 0.2376 - acc: 0.9389 - val_loss: 2.1217 - val_acc: 0.4361\n",
      "Epoch 34/50\n",
      "1440/1440 [==============================] - 7s 5ms/step - loss: 0.1655 - acc: 0.9667 - val_loss: 2.2858 - val_acc: 0.4556\n",
      "Epoch 35/50\n",
      "1440/1440 [==============================] - 7s 5ms/step - loss: 0.2171 - acc: 0.9368 - val_loss: 2.3519 - val_acc: 0.4972\n",
      "Epoch 36/50\n",
      "1440/1440 [==============================] - 7s 5ms/step - loss: 0.1731 - acc: 0.9604 - val_loss: 2.4039 - val_acc: 0.4167\n",
      "Epoch 37/50\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.1620 - acc: 0.9569 - val_loss: 2.4618 - val_acc: 0.4556\n",
      "Epoch 38/50\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.1529 - acc: 0.9632 - val_loss: 2.3762 - val_acc: 0.4556\n",
      "Epoch 39/50\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.1624 - acc: 0.9632 - val_loss: 2.3650 - val_acc: 0.4694\n",
      "Epoch 40/50\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0955 - acc: 0.9854 - val_loss: 2.5386 - val_acc: 0.4306\n",
      "Epoch 41/50\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.1810 - acc: 0.9444 - val_loss: 2.4783 - val_acc: 0.4528\n",
      "Epoch 42/50\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0770 - acc: 0.9896 - val_loss: 2.5124 - val_acc: 0.4778\n",
      "Epoch 43/50\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0650 - acc: 0.9951 - val_loss: 3.0088 - val_acc: 0.4417\n",
      "Epoch 44/50\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.1759 - acc: 0.9556 - val_loss: 2.6030 - val_acc: 0.4861\n",
      "Epoch 45/50\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0927 - acc: 0.9750 - val_loss: 2.6412 - val_acc: 0.4694\n",
      "Epoch 46/50\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0474 - acc: 0.9972 - val_loss: 2.7412 - val_acc: 0.4750\n",
      "Epoch 47/50\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0364 - acc: 0.9972 - val_loss: 3.1910 - val_acc: 0.4361\n",
      "Epoch 48/50\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.1867 - acc: 0.9514 - val_loss: 2.8033 - val_acc: 0.4694\n",
      "Epoch 49/50\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0304 - acc: 1.0000 - val_loss: 2.8926 - val_acc: 0.4917\n",
      "Epoch 50/50\n",
      "1440/1440 [==============================] - 6s 4ms/step - loss: 0.0240 - acc: 1.0000 - val_loss: 2.9077 - val_acc: 0.4833\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import GRU\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim = n_words, output_dim = 100, input_length = max_sentence_length))\n",
    "model.add(GRU(100))\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])\n",
    "history = model.fit(x_train, y_train, epochs=50, batch_size=128, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(x_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.942488350868225"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.455"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SOURCES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/susanli2016/Machine-Learning-with-Python/blob/master/Consumer_complaints.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://catalog.data.gov/dataset/consumer-complaint-database"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
